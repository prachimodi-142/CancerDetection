{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EPOGJPDvT-bB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asineesh/I2I/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import utils, models,datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DGo_HCm0ULxd"
   },
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels,intermediate_channels,kernel_size=1, stride=1, padding=0,bias=False)\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels,kernel_size=3, stride=stride,padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(intermediate_channels,intermediate_channels * self.expansion,kernel_size=1,stride=1,padding=0,bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.conv1(x)        \n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)        \n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)       \n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, layers[0], intermediate_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layer(block, layers[1], intermediate_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layer(block, layers[2], intermediate_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layer(block, layers[3], intermediate_channels=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Conv2d(self.in_channels,intermediate_channels * 4,kernel_size=1,stride=stride,bias=False)               \n",
    "\n",
    "        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride))\n",
    "\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wpg6fUe0UB36"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((96,96)),\n",
    "                                      transforms.ColorJitter(brightness=.5, saturation=.25,hue=.1, contrast=.5),\n",
    "                                      transforms.RandomAffine(10, (0.05, 0.05)),\n",
    "                                      transforms.RandomHorizontalFlip(.5),\n",
    "                                      transforms.RandomVerticalFlip(.5),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.6716241, 0.48636872, 0.60884315],\n",
    "                                                           [0.27210504, 0.31001145, 0.2918652])\n",
    "        ])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((96,96)),        \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.6716241, 0.48636872, 0.60884315],\n",
    "                                 [0.27210504, 0.31001145, 0.2918652])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qo59LMtkUEzt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245760"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.ImageFolder(root=\"PCam/Pcam_Train/Pcam_Train\",transform=train_transform)\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rDZ5FmViUHAa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40960"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = datasets.ImageFolder(root=\"PCam/Pcam_Test_192/Pcam_Test_192\",transform=test_transform)\n",
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4CtoNd7UIzF",
    "outputId": "1446f726-49e3-4f79-b721-377d347e3c8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LPvuTbYaVnYb"
   },
   "outputs": [],
   "source": [
    "model = ResNet(block, [3, 4, 6, 3], 3, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VEqhooSSVuHY"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "torch.manual_seed(42)\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True,num_workers=24)\n",
    "test_loader = DataLoader(valid_data, batch_size=128, shuffle=True,num_workers=24)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eaQ3r3M5Vypb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:28<00:00,  3.78it/s, loss=0.446]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 Train accuracy: 75.667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 Test accuracy: 79.419%\n",
      "\n",
      "Duration: 554 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:09<00:00,  3.93it/s, loss=0.499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 Train accuracy: 80.142%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 Test accuracy: 81.118%\n",
      "\n",
      "Duration: 1089 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:14<00:00,  3.89it/s, loss=0.42] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 Train accuracy: 82.306%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 Test accuracy: 82.610%\n",
      "\n",
      "Duration: 1629 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:07<00:00,  3.94it/s, loss=0.298]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 Train accuracy: 84.016%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 Test accuracy: 82.930%\n",
      "\n",
      "Duration: 2164 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:06<00:00,  3.95it/s, loss=0.281]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 Train accuracy: 85.331%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 Test accuracy: 83.240%\n",
      "\n",
      "Duration: 2696 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:07<00:00,  3.94it/s, loss=0.294]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5 Train accuracy: 86.792%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5 Test accuracy: 84.839%\n",
      "\n",
      "Duration: 3230 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:07<00:00,  3.94it/s, loss=0.199]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6 Train accuracy: 87.749%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6 Test accuracy: 83.850%\n",
      "\n",
      "Duration: 3762 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:06<00:00,  3.95it/s, loss=0.302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7 Train accuracy: 88.544%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7 Test accuracy: 86.060%\n",
      "\n",
      "Duration: 4294 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:04<00:00,  3.96it/s, loss=0.212]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8 Train accuracy: 89.080%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8 Test accuracy: 86.965%\n",
      "\n",
      "Duration: 4824 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [08:01<00:00,  3.99it/s, loss=0.254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9 Train accuracy: 89.594%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9 Test accuracy: 85.908%\n",
      "\n",
      "Duration: 5350 seconds\n",
      "Final Test accuracy: 85.908%\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()     \n",
    "    \n",
    "train_losses = []\n",
    "train_correct = []\n",
    "test_correct = []\n",
    "best_acc = 0.0\n",
    "    \n",
    "for epoch in range(10):\n",
    "        trn_corr = 0\n",
    "        tst_corr = 0\n",
    "        loop = tqdm(train_loader)\n",
    "                \n",
    "        # Run the training batches\n",
    "        for b, (X_train, y_train) in enumerate(loop):       \n",
    "            \n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "            y_pred = model(X_train)\n",
    "            loss = criterion(y_pred, y_train)\n",
    "     \n",
    "            # Tally the number of correct predictions\n",
    "            predicted = torch.max(y_pred.data, 1)[1]\n",
    "            batch_corr = (predicted == y_train).sum()\n",
    "            trn_corr += batch_corr\n",
    "            \n",
    "            # Update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loop.set_postfix(loss=loss.item())   \n",
    "           \n",
    "    \n",
    "            train_losses.append(loss)\n",
    "            train_correct.append(trn_corr)\n",
    "        \n",
    "        print(f'epoch: {epoch:2} Train accuracy: {train_correct[-1].item()*100/len(train_data):.3f}%')\n",
    "        \n",
    "        # Run the testing batches\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for b, (X_test, y_test) in enumerate(test_loader):\n",
    "                \n",
    "                X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "                \n",
    "                # Apply the model\n",
    "                \n",
    "                y_val = model(X_test)              \n",
    "                \n",
    "                # Tally the number of correct predictions\n",
    "                predicted = torch.max(y_val.data, 1)[1] \n",
    "                tst_corr += (predicted == y_test).sum()\n",
    "                test_correct.append(tst_corr)               \n",
    "        \n",
    "        \n",
    "        print(f'epoch: {epoch:2} Test accuracy: {test_correct[-1].item()*100/len(valid_data):.3f}%')\n",
    "        test_acc = test_correct[-1].item()*100/len(valid_data)\n",
    "        if test_acc>best_acc:\n",
    "            torch.save(model.state_dict(), \"resnet96_0.0005_\"+str(test_acc)+\"_\"+str(epoch)+\" .pt\")\n",
    "            best_acc = test_acc\n",
    "       \n",
    "        print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed    \n",
    "    \n",
    "print(f'Final Test accuracy: {test_correct[-1].item()*100/len(valid_data):.3f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "I2I",
   "language": "python",
   "name": "i2i"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
