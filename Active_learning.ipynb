{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoWQ8LMgM8LkGrJhrzFEyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachimodi-142/CancerDetection/blob/master/Active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNs2sVF3L0QI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import utils, models,datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from groupy.gconv.pytorch_gconv import P4MConvZ2, P4MConvP4M\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_getitem(self, index: int):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (sample, target) where target is class_index of the target class.\n",
        "        \"\"\"\n",
        "        path, target = self.samples[index]\n",
        "        sample = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return sample, target, index\n"
      ],
      "metadata": {
        "id": "HT2bNL2rMXwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.ImageFolder.__getitem__ = new_getitem"
      ],
      "metadata": {
        "id": "GTOxD65dMbMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(self, in_planes, intermediate_planes, identity_downsample=None, stride=1):\n",
        "        super().__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = P4MConvP4M(in_planes, intermediate_planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(intermediate_planes)\n",
        "        self.conv2 = P4MConvP4M(intermediate_planes, intermediate_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(intermediate_planes)\n",
        "        self.conv3 = P4MConvP4M(intermediate_planes,intermediate_planes * self.expansion,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(intermediate_planes * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 23\n",
        "        self.conv1 = P4MConvZ2(3, 23, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(23)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=(1,3,3), stride=(1,2,2), padding=(0,1,1))\n",
        "\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1 = self._make_layer(block, layers[0], intermediate_plane=23, stride=1)\n",
        "        self.layer2 = self._make_layer(block, layers[1], intermediate_plane=45, stride=2)\n",
        "        self.layer3 = self._make_layer(block, layers[2], intermediate_plane=91, stride=2)\n",
        "        self.layer4 = self._make_layer(block, layers[3], intermediate_plane=181, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(181*8* 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_plane, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_planes != intermediate_plane * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                P4MConvP4M(self.in_planes,intermediate_plane * 4,kernel_size=1,stride=stride,bias=False),\n",
        "            nn.BatchNorm3d(intermediate_plane * 4)\n",
        "\n",
        "            )\n",
        "\n",
        "        layers.append(block(self.in_planes, intermediate_plane, identity_downsample, stride))\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_planes = intermediate_plane * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_planes, intermediate_plane))\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "TB6OaJXoMfvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def least_confidence_query(model, device, data_loader, query_size):\n",
        "\n",
        "    confidences = []\n",
        "    indices = []\n",
        "    model.eval()\n",
        "    loopt = tqdm(data_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for b, (data, _,idx) in enumerate(loopt):\n",
        "            logits = model(data.to(device))\n",
        "            probabilities = F.softmax(logits, dim=1) #The probability of all the classes adds up to one\n",
        "\n",
        "            # Keep only the top class confidence for each sample\n",
        "            most_probable = torch.max(probabilities, dim=1)[0]\n",
        "            confidences.extend(most_probable.cpu().tolist()) #storing the confidence values\n",
        "            indices.extend(idx.tolist())\n",
        "\n",
        "    conf = np.asarray(confidences)\n",
        "    ind = np.asarray(indices)\n",
        "    sorted_pool = np.argsort(conf) #sorting the confidence values and returning their indices\n",
        "\n",
        "    return ind[sorted_pool][0:query_size] #The first bracket reorders the \"ind\" array"
      ],
      "metadata": {
        "id": "oXQ5hu33Mpab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_the_oracle(model, device, dataset, tracker, query_size,batch_size):\n",
        "\n",
        "    unlabeled_idx = np.nonzero(tracker)[0] #returns the indices of images not labled\n",
        "\n",
        "    # Select a pool of samples to query from\n",
        "    pool_loader = DataLoader(dataset, batch_size=batch_size,sampler=SubsetRandomSampler(unlabeled_idx),num_workers=24)\n",
        "\n",
        "    sample_idx = least_confidence_query(model, device, pool_loader, query_size) # Return the indices corresponding to the lowest confidences\n",
        "\n",
        "    # Query the samples, one at a time\n",
        "    for sample in sample_idx:\n",
        "      tracker[sample] = 0\n",
        "    return tracker"
      ],
      "metadata": {
        "id": "VSy1e-W3MvhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "\n",
        "        data, target, _ = batch\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "tMAwZQR_MwWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, criterion,test_loader):\n",
        "          model.eval()\n",
        "          loopt = tqdm(test_loader)\n",
        "          tst_corr = 0\n",
        "          with torch.no_grad():\n",
        "            for b, (X_test, y_test,_) in enumerate(loopt):\n",
        "                X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "                # Apply the model\n",
        "                y_val = model(X_test)\n",
        "\n",
        "                loss = criterion(y_val, y_test)\n",
        "                loopt.set_postfix(loss=loss.item())\n",
        "\n",
        "                # Tally the number of correct predictions\n",
        "                predicted = torch.max(y_val.data, 1)[1]\n",
        "                tst_corr = tst_corr + (predicted == y_test).sum()\n",
        "\n",
        "\n",
        "\n",
        "          print(f'Test accuracy: {tst_corr*100/len(test_loader.dataset):.3f}%')\n",
        "          return tst_corr*100/len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "Q-u0oniiMzMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([transforms.Resize((96,96)),\n",
        "                                      transforms.ColorJitter(brightness=.5, saturation=.25,hue=.1, contrast=.5),\n",
        "                                      transforms.RandomAffine(10, (0.05, 0.05)),\n",
        "                                      transforms.RandomHorizontalFlip(.5),\n",
        "                                      transforms.RandomVerticalFlip(.5),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.6716241, 0.48636872, 0.60884315],\n",
        "                                                           [0.27210504, 0.31001145, 0.2918652])\n",
        "        ])\n",
        "\n",
        "test_transform = transforms.Compose([transforms.Resize((96,96)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.6716241, 0.48636872, 0.60884315],\n",
        "                                 [0.27210504, 0.31001145, 0.2918652])\n",
        "        ])"
      ],
      "metadata": {
        "id": "pkD66iUxM22l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "HdyZW9zxM9Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(\"PCam/Pcam_Train/Pcam_Train\",transform = train_transform)\n",
        "print(len(train_data))\n"
      ],
      "metadata": {
        "id": "JkIImTO3NBBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.ImageFolder(\"PCam/Pcam_Test_192/Pcam_Test_192\",transform = test_transform)\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "3i9KtgFINCBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "torch.manual_seed(42)\n",
        "train_loader = DataLoader(train_data, batch_size=48, shuffle=True,num_workers=24)\n",
        "test_loader = DataLoader(test_data, batch_size=48, shuffle=True,num_workers=24)\n",
        "model = ResNet(block, [3, 4, 6, 3], 3, 2)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "tracker = np.ones((len(train_data)))"
      ],
      "metadata": {
        "id": "QFMlXw01NE2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_acc = 0.0\n",
        "for i in range(10):\n",
        "    print(f\"Query \"+str(i))\n",
        "    tracker = query_the_oracle(model, device, train_data, tracker, query_size=6000,batch_size=48)\n",
        "    labeled_idx = np.where(tracker == 0)[0]\n",
        "    print(len(labeled_idx))\n",
        "    labeled_loader = DataLoader(train_data, batch_size=48,sampler=SubsetRandomSampler(labeled_idx),num_workers=24)\n",
        "    epochs  = 5 if i>4 else 3\n",
        "    for k in range(epochs):\n",
        "        train_loss = train(model, device, labeled_loader, optimizer, criterion)\n",
        "        current_test_acc = test(model, device,criterion, test_loader)\n",
        "        if current_test_acc>best_acc:\n",
        "            torch.save(model.state_dict(), \"resnet50_active_\"+str(current_test_acc)+\"_\"+str(i)+\".pt\")\n",
        "            best_acc = current_test_acc"
      ],
      "metadata": {
        "id": "1H1OlmfjNH7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}